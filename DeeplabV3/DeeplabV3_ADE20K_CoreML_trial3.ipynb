{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeeplabV3_ADE20K_CoreML_trial3.ipynb","provenance":[{"file_id":"12045pQxvvZfVor01kl2KG5VEGfaNKo7B","timestamp":1628704678315},{"file_id":"11jj-GA3a0hHBl-R-IhjRRm9DayOzrpmO","timestamp":1628348945436},{"file_id":"1z-pfsm6aCxw45jEJw33wdsyDPe3OaUKc","timestamp":1627889945063},{"file_id":"1uo9yP5z9UeAyvjaHAbhuiAHXnlXrTWTO","timestamp":1627648027406}],"collapsed_sections":[],"mount_file_id":"1z-pfsm6aCxw45jEJw33wdsyDPe3OaUKc","authorship_tag":"ABX9TyMVGufWn99Bu1Tk5mlLpGsX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Y1OFLLcjOgGa"},"source":["# About\n","\n","Convert deeplabv3_mnv2_ade20k_train_2018_12_03 to Core ML\n","\n","The model can be converted successfully and produces plausible result without modifying any layers. \n","\n","Model is quantized to 8 bits. On iPhone Xs, latency reduced from 790 ms (no quantization) to 220 ms."]},{"cell_type":"markdown","metadata":{"id":"LCSQQFtAtvI0"},"source":["# Download model and setup enviroments"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MWvmw6-SYmH3","executionInfo":{"status":"ok","timestamp":1628704753204,"user_tz":-120,"elapsed":1160,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"e2fd9901-d04d-432d-f4e9-88ac94730cc0"},"source":["!rm -rf deeplabv3_mnv2_ade20k_train_2018_12_03\n","!wget http://download.tensorflow.org/models/deeplabv3_mnv2_ade20k_train_2018_12_03.tar.gz\n","!tar -zxvf deeplabv3_mnv2_ade20k_train_2018_12_03.tar.gz"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2021-08-11 17:59:11--  http://download.tensorflow.org/models/deeplabv3_mnv2_ade20k_train_2018_12_03.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.119.128, 2a00:1450:4013:c00::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.119.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 26028742 (25M) [application/x-tar]\n","Saving to: ‘deeplabv3_mnv2_ade20k_train_2018_12_03.tar.gz’\n","\n","deeplabv3_mnv2_ade2 100%[===================>]  24.82M  69.2MB/s    in 0.4s    \n","\n","2021-08-11 17:59:12 (69.2 MB/s) - ‘deeplabv3_mnv2_ade20k_train_2018_12_03.tar.gz’ saved [26028742/26028742]\n","\n","deeplabv3_mnv2_ade20k_train_2018_12_03/\n","deeplabv3_mnv2_ade20k_train_2018_12_03/model.ckpt.index\n","deeplabv3_mnv2_ade20k_train_2018_12_03/frozen_inference_graph.pb\n","deeplabv3_mnv2_ade20k_train_2018_12_03/model.ckpt.data-00000-of-00001\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"juNKhNFf47RU","executionInfo":{"status":"ok","timestamp":1628704760041,"user_tz":-120,"elapsed":6839,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"a409cf37-16f3-47b3-fc8a-a73950443113"},"source":["%tensorflow_version 1.x\n","\n","!pip install coremltools==4.1"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Collecting coremltools==4.1\n","  Downloading coremltools-4.1-cp37-none-manylinux1_x86_64.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 16.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<1.20,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.19.5)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (21.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (21.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (4.41.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.4.1)\n","Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (3.17.3)\n","Collecting attr\n","  Downloading attr-0.3.1.tar.gz (1.7 kB)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools==4.1) (2.4.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools==4.1) (1.2.1)\n","Building wheels for collected packages: attr\n","  Building wheel for attr (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for attr: filename=attr-0.3.1-py3-none-any.whl size=2457 sha256=dd934525cc1d1d33a6ff39d12db39dd92be46b7f4596807f57758c58fec32209\n","  Stored in directory: /root/.cache/pip/wheels/3b/5d/58/41fbe92f47031641008bd8559ee89e58bf0f123f9c18dea1cb\n","Successfully built attr\n","Installing collected packages: attr, coremltools\n","Successfully installed attr-0.3.1 coremltools-4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9BlsvWDA5KYD","executionInfo":{"status":"ok","timestamp":1628704770843,"user_tz":-120,"elapsed":10806,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"12208a08-e3a8-476a-a2c6-68662dccfb5c"},"source":["import sys\n","print(sys.version)\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","import coremltools as ct\n","print(ct.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["3.7.11 (default, Jul  3 2021, 18:01:19) \n","[GCC 7.5.0]\n","1.15.2\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:scikit-learn version 0.22.2.post1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n","WARNING:root:TensorFlow version 1.15.2 detected. Last version known to be fully compatible is 1.15.0 .\n","WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"],"name":"stderr"},{"output_type":"stream","text":["4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4CN7TBVOMbsL"},"source":["# Inspect the graph"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_ysyiKIMPtn","executionInfo":{"status":"ok","timestamp":1628704771647,"user_tz":-120,"elapsed":824,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"0e3f0be7-1786-4cef-bc96-845c2a83b300"},"source":["def load_frozen_graph(path):\n","  with tf.io.gfile.GFile(path, \"rb\") as f:\n","    graph_def = tf.compat.v1.GraphDef()\n","    graph_def.ParseFromString(f.read())\n","\n","    return graph_def\n","\n","def export_ops_name(the_graph, filename):\n","  with open(filename, \"w\") as text_file:\n","    ops = the_graph.get_operations()\n","    N = len(ops)\n","    for i in range(N):\n","      text_file.write('\\n\\nop id {} , op type: \"{}\"'.format(str(i), ops[i].type))\n","      \n","      text_file.write('\\ninput(s):'),\n","      for x in ops[i].inputs:\n","        text_file.write(\"name = {}, shape: {}, \".format(x.name, x.get_shape()))\n","      \n","      text_file.write('\\noutput(s):'),\n","      for x in ops[i].outputs:\n","        text_file.write(\"name = {}, shape: {},\".format(x.name, x.get_shape()))\n","  print('Exported to:', filename)\n","\n","\n","model_name = 'deeplabv3_mnv2_ade20k_train_2018_12_03'\n","input_file = f'{model_name}/frozen_inference_graph.pb'\n","\n","with tf.Session(graph=tf.Graph()) as sess:\n","  graph_def = load_frozen_graph(input_file)\n","  tf.import_graph_def(graph_def, name=\"\")\n","  the_graph = tf.compat.v1.get_default_graph()\n","  export_ops_name(the_graph, f'{model_name}_ops.txt')\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Exported to: deeplabv3_mnv2_ade20k_train_2018_12_03_ops.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gCosYrU6Mfnl"},"source":["# Convert the TensorFlow model to Core ML."]},{"cell_type":"code","metadata":{"id":"uFy-1CCg7n8-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628705268690,"user_tz":-120,"elapsed":4899,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"d62ca147-3795-4855-ee0f-53edbfd3fdc2"},"source":["input_name = \"ImageTensor\"\n","output_name = \"SemanticPredictions\"\n","\n","input_w = 513\n","input_h = 513\n","\n","tfmodel = 'deeplabv3_mnv2_ade20k_train_2018_12_03/frozen_inference_graph.pb'\n","\n","image_input = ct.ImageType(name=input_name,\n","                           shape=(1, input_h, input_w, 3),\n","                           bias=[0,0,0], \n","                           scale=1)\n","\n","coreml_model = ct.convert(\n","    tfmodel,\n","    source='tensorflow',\n","    inputs=[image_input],\n","    outputs=[output_name]\n",")\n","\n","print(coreml_model)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Running TensorFlow Graph Passes: 100%|██████████| 7/7 [00:00<00:00, 17.83 passes/s]\n","Converting Frontend ==> MIL Ops: 100%|██████████| 721/721 [00:01<00:00, 452.50 ops/s]\n","Running MIL optimization passes: 100%|██████████| 18/18 [00:01<00:00, 15.45 passes/s]\n","WARNING:root:Output var SemanticPredictions of type i32 in function main is cast to type fp32\n","Translating MIL ==> MLModel Ops:   0%|          | 0/877 [00:00<?, ? ops/s]WARNING:root:Const Reshape was already added.\n","Translating MIL ==> MLModel Ops: 100%|██████████| 877/877 [00:00<00:00, 2290.36 ops/s]\n"],"name":"stderr"},{"output_type":"stream","text":["input {\n","  name: \"ImageTensor\"\n","  type {\n","    imageType {\n","      width: 513\n","      height: 513\n","      colorSpace: RGB\n","    }\n","  }\n","}\n","output {\n","  name: \"SemanticPredictions\"\n","  type {\n","    multiArrayType {\n","      dataType: FLOAT32\n","    }\n","  }\n","}\n","metadata {\n","  userDefined {\n","    key: \"com.github.apple.coremltools.source\"\n","    value: \"tensorflow==1.15.2\"\n","  }\n","  userDefined {\n","    key: \"com.github.apple.coremltools.version\"\n","    value: \"4.1\"\n","  }\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JryQm4E9alEG"},"source":["# Quantize the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dhjb-6Qpac3c","executionInfo":{"status":"ok","timestamp":1628705539039,"user_tz":-120,"elapsed":7173,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"028c8fb5-b2c2-4b84-dff1-4080269de1ed"},"source":["from coremltools.models.neural_network import quantization_utils\n","\n","# allowed values of nbits = 16, 8, 7, 6, ...., 1\n","spec = quantization_utils.quantize_weights(coreml_model, nbits=8)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Quantizing using linear quantization\n","Optimizing Neural Network before Quantization:\n","Fused MobilenetV2/Conv/Conv2Dx->batch_norm_118\n","Fused MobilenetV2/expanded_conv/depthwise/depthwisex->batch_norm_119\n","Fused MobilenetV2/expanded_conv/project/Conv2Dx->batch_norm_120\n","Fused MobilenetV2/expanded_conv_1/expand/Conv2Dx->batch_norm_121\n","Fused MobilenetV2/expanded_conv_1/depthwise/depthwisex->batch_norm_122\n","Fused MobilenetV2/expanded_conv_1/project/Conv2Dx->batch_norm_123\n","Fused MobilenetV2/expanded_conv_2/expand/Conv2Dx->batch_norm_124\n","Fused MobilenetV2/expanded_conv_2/depthwise/depthwisex->batch_norm_125\n","Fused MobilenetV2/expanded_conv_2/project/Conv2Dx->batch_norm_126\n","Fused decoder/feature_projection0/Conv2Dx->batch_norm_127\n","Fused MobilenetV2/expanded_conv_3/expand/Conv2Dx->batch_norm_128\n","Fused MobilenetV2/expanded_conv_3/depthwise/depthwisex->batch_norm_129\n","Fused MobilenetV2/expanded_conv_3/project/Conv2Dx->batch_norm_130\n","Fused MobilenetV2/expanded_conv_4/expand/Conv2Dx->batch_norm_131\n","Fused MobilenetV2/expanded_conv_4/depthwise/depthwisex->batch_norm_132\n","Fused MobilenetV2/expanded_conv_4/project/Conv2Dx->batch_norm_133\n","Fused MobilenetV2/expanded_conv_5/expand/Conv2Dx->batch_norm_134\n","Fused MobilenetV2/expanded_conv_5/depthwise/depthwisex->batch_norm_135\n","Fused MobilenetV2/expanded_conv_5/project/Conv2Dx->batch_norm_136\n","Fused MobilenetV2/expanded_conv_6/expand/Conv2Dx->batch_norm_137\n","Fused MobilenetV2/expanded_conv_6/depthwise/depthwisex->batch_norm_138\n","Fused MobilenetV2/expanded_conv_6/project/Conv2Dx->batch_norm_139\n","Fused MobilenetV2/expanded_conv_7/expand/Conv2Dx->batch_norm_140\n","Fused MobilenetV2/expanded_conv_7/depthwise/depthwisex->batch_norm_141\n","Fused MobilenetV2/expanded_conv_7/project/Conv2Dx->batch_norm_142\n","Fused MobilenetV2/expanded_conv_8/expand/Conv2Dx->batch_norm_143\n","Fused MobilenetV2/expanded_conv_8/depthwise/depthwisex->batch_norm_144\n","Fused MobilenetV2/expanded_conv_8/project/Conv2Dx->batch_norm_145\n","Fused MobilenetV2/expanded_conv_9/expand/Conv2Dx->batch_norm_146\n","Fused MobilenetV2/expanded_conv_9/depthwise/depthwisex->batch_norm_147\n","Fused MobilenetV2/expanded_conv_9/project/Conv2Dx->batch_norm_148\n","Fused MobilenetV2/expanded_conv_10/expand/Conv2Dx->batch_norm_149\n","Fused MobilenetV2/expanded_conv_10/depthwise/depthwisex->batch_norm_150\n","Fused MobilenetV2/expanded_conv_10/project/Conv2Dx->batch_norm_151\n","Fused MobilenetV2/expanded_conv_11/expand/Conv2Dx->batch_norm_152\n","Fused MobilenetV2/expanded_conv_11/depthwise/depthwisex->batch_norm_153\n","Fused MobilenetV2/expanded_conv_11/project/Conv2Dx->batch_norm_154\n","Fused MobilenetV2/expanded_conv_12/expand/Conv2Dx->batch_norm_155\n","Fused MobilenetV2/expanded_conv_12/depthwise/depthwisex->batch_norm_156\n","Fused MobilenetV2/expanded_conv_12/project/Conv2Dx->batch_norm_157\n","Fused MobilenetV2/expanded_conv_13/expand/Conv2Dx->batch_norm_158\n","Fused MobilenetV2/expanded_conv_13/depthwise/depthwisex->batch_norm_159\n","Fused MobilenetV2/expanded_conv_13/project/Conv2Dx->batch_norm_160\n","Fused MobilenetV2/expanded_conv_14/expand/Conv2Dx->batch_norm_161\n","Fused MobilenetV2/expanded_conv_14/depthwise/depthwisex->batch_norm_162\n","Fused MobilenetV2/expanded_conv_14/project/Conv2Dx->batch_norm_163\n","Fused MobilenetV2/expanded_conv_15/expand/Conv2Dx->batch_norm_164\n","Fused MobilenetV2/expanded_conv_15/depthwise/depthwisex->batch_norm_165\n","Fused MobilenetV2/expanded_conv_15/project/Conv2Dx->batch_norm_166\n","Fused MobilenetV2/expanded_conv_16/expand/Conv2Dx->batch_norm_167\n","Fused MobilenetV2/expanded_conv_16/depthwise/depthwisex->batch_norm_168\n","Fused MobilenetV2/expanded_conv_16/project/Conv2Dx->batch_norm_169\n","Fused aspp0/Conv2Dx->batch_norm_170\n","Fused image_pooling/Conv2Dx->batch_norm_171\n","Fused concat_projection/Conv2Dx->batch_norm_172\n","Fused decoder/decoder_conv0_depthwise/depthwisex->batch_norm_173\n","Fused decoder/decoder_conv0_pointwise/Conv2Dx->batch_norm_174\n","Fused decoder/decoder_conv1_depthwise/depthwisex->batch_norm_175\n","Fused decoder/decoder_conv1_pointwise/Conv2Dx->batch_norm_176\n","Finished optimizing network. Quantizing neural network..\n","Quantizing layer MobilenetV2/Conv/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_1/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_1/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_1/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_2/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_2/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_2/project/Conv2Dx\n","Quantizing layer decoder/feature_projection0/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_3/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_3/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_3/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_4/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_4/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_4/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_5/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_5/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_5/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_6/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_6/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_6/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_7/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_7/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_7/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_8/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_8/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_8/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_9/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_9/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_9/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_10/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_10/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_10/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_11/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_11/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_11/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_12/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_12/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_12/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_13/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_13/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_13/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_14/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_14/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_14/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_15/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_15/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_15/project/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_16/expand/Conv2Dx\n","Quantizing layer MobilenetV2/expanded_conv_16/depthwise/depthwisex\n","Quantizing layer MobilenetV2/expanded_conv_16/project/Conv2Dx\n","Quantizing layer aspp0/Conv2Dx\n","Quantizing layer image_pooling/Conv2Dx\n","Quantizing layer concat_projection/Conv2Dx\n","Quantizing layer decoder/decoder_conv0_depthwise/depthwisex\n","Quantizing layer decoder/decoder_conv0_pointwise/Conv2Dx\n","Quantizing layer decoder/decoder_conv1_depthwise/depthwisex\n","Quantizing layer decoder/decoder_conv1_pointwise/Conv2Dx\n","Quantizing layer logits/semantic/BiasAdd\n","WARNING! Unable to return a quantized MLModel instance sinceOS != macOS 10.14 or later\n","Returning quantized model specification instead\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4f8J1VBhp4U","executionInfo":{"status":"ok","timestamp":1628705586965,"user_tz":-120,"elapsed":416,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"a5fb3b1b-3895-43d3-f4d9-d2664153ace7"},"source":["# Fill in the descriptions and metadata.\n","spec.description.metadata.versionString = \"2021-08-11\"\n","spec.description.metadata.shortDescription = \"deeplabv3_mnv2_ade20k_train_2018_12_03\"\n","spec.description.metadata.author = \"Converted by Anh\"\n","\n","\n","# Rename inputs and outputs.\n","new_input_name = \"image\"\n","new_output_name = \"scores\"\n","\n","ct.utils.rename_feature(spec, input_name, new_input_name)\n","ct.utils.rename_feature(spec, output_name, new_output_name)\n","\n","spec.description.input[0].shortDescription = \"Input image\"\n","spec.description.output[0].shortDescription = \"Segmentation map\"\n","\n","# Fix up the output shape and make it INT32.\n","spec.description.output[0].type.multiArrayType.shape.append(input_h)\n","spec.description.output[0].type.multiArrayType.shape.append(input_w)\n","spec.description.output[0].type.multiArrayType.dataType = ct.proto.FeatureTypes_pb2.ArrayFeatureType.INT32\n","\n","\n","print(spec.description)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["input {\n","  name: \"image\"\n","  shortDescription: \"Input image\"\n","  type {\n","    imageType {\n","      width: 513\n","      height: 513\n","      colorSpace: RGB\n","    }\n","  }\n","}\n","output {\n","  name: \"scores\"\n","  shortDescription: \"Segmentation map\"\n","  type {\n","    multiArrayType {\n","      shape: 513\n","      shape: 513\n","      dataType: INT32\n","    }\n","  }\n","}\n","metadata {\n","  shortDescription: \"deeplabv3_mnv2_ade20k_train_2018_12_03\"\n","  versionString: \"2021-08-11\"\n","  author: \"Converted by Anh\"\n","  userDefined {\n","    key: \"com.github.apple.coremltools.source\"\n","    value: \"tensorflow==1.15.2\"\n","  }\n","  userDefined {\n","    key: \"com.github.apple.coremltools.version\"\n","    value: \"4.1\"\n","  }\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6hzP1UusNsOa"},"source":["# Add labels"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZpwlX3ZIlrno","executionInfo":{"status":"ok","timestamp":1628705622323,"user_tz":-120,"elapsed":368,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"58c76cea-53bb-4068-cdbd-9f2bc7805d2a"},"source":["labels = \"\"\"\n","wall\n","building, edifice\n","sky\n","floor, flooring\n","tree\n","ceiling\n","road, route\n","bed \n","windowpane, window \n","grass\n","cabinet\n","sidewalk, pavement\n","person, individual, someone, somebody, mortal, soul\n","earth, ground\n","door, double door\n","table\n","mountain, mount\n","plant, flora, plant life\n","curtain, drape, drapery, mantle, pall\n","chair\n","car, auto, automobile, machine, motorcar\n","water\n","painting, picture\n","sofa, couch, lounge\n","shelf\n","house\n","sea\n","mirror\n","rug, carpet, carpeting\n","field\n","armchair\n","seat\n","fence, fencing\n","desk\n","rock, stone\n","wardrobe, closet, press\n","lamp\n","bathtub, bathing tub, bath, tub\n","railing, rail\n","cushion\n","base, pedestal, stand\n","box\n","column, pillar\n","signboard, sign\n","chest of drawers, chest, bureau, dresser\n","counter\n","sand\n","sink\n","skyscraper\n","fireplace, hearth, open fireplace\n","refrigerator, icebox\n","grandstand, covered stand\n","path\n","stairs, steps\n","runway\n","case, display case, showcase, vitrine\n","pool table, billiard table, snooker table\n","pillow\n","screen door, screen\n","stairway, staircase\n","river\n","bridge, span\n","bookcase\n","blind, screen\n","coffee table, cocktail table\n","toilet, can, commode, crapper, pot, potty, stool, throne\n","flower\n","book\n","hill\n","bench\n","countertop\n","stove, kitchen stove, range, kitchen range, cooking stove\n","palm, palm tree\n","kitchen island\n","computer, computing machine, computing device, data processor, electronic computer, information processing system\n","swivel chair\n","boat\n","bar\n","arcade machine\n","hovel, hut, hutch, shack, shanty\n","bus, autobus, coach, charabanc, double-decker, jitney, motorbus, motorcoach, omnibus, passenger vehicle\n","towel\n","light, light source\n","truck, motortruck\n","tower\n","chandelier, pendant, pendent\n","awning, sunshade, sunblind\n","streetlight, street lamp\n","booth, cubicle, stall, kiosk\n","television, television receiver, television set, tv, tv set, idiot box, boob tube, telly, goggle box\n","airplane, aeroplane, plane\n","dirt track\n","apparel, wearing apparel, dress, clothes\n","pole\n","land, ground, soil\n","bannister, banister, balustrade, balusters, handrail\n","escalator, moving staircase, moving stairway\n","ottoman, pouf, pouffe, puff, hassock\n","bottle\n","buffet, counter, sideboard\n","poster, posting, placard, notice, bill, card\n","stage\n","van\n","ship\n","fountain\n","conveyer belt, conveyor belt, conveyer, conveyor, transporter\n","canopy\n","washer, automatic washer, washing machine\n","plaything, toy\n","swimming pool, swimming bath, natatorium\n","stool\n","barrel, cask\n","basket, handbasket\n","waterfall, falls\n","tent, collapsible shelter\n","bag\n","minibike, motorbike\n","cradle\n","oven\n","ball\n","food, solid food\n","step, stair\n","tank, storage tank\n","trade name, brand name, brand, marque\n","microwave, microwave oven\n","pot, flowerpot\n","animal, animate being, beast, brute, creature, fauna\n","bicycle, bike, wheel, cycle \n","lake\n","dishwasher, dish washer, dishwashing machine\n","screen, silver screen, projection screen\n","blanket, cover\n","sculpture\n","hood, exhaust hood\n","sconce\n","vase\n","traffic light, traffic signal, stoplight\n","tray\n","ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\n","fan\n","pier, wharf, wharfage, dock\n","crt screen\n","plate\n","monitor, monitoring device\n","bulletin board, notice board\n","shower\n","radiator\n","glass, drinking glass\n","clock\n","flag\n","\"\"\"\n"," \n","labels_list = labels.split('\\n')\n","print(len(labels_list))\n","print(labels_list)\n","assert(len(labels_list) == 152)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["152\n","['', 'wall', 'building, edifice', 'sky', 'floor, flooring', 'tree', 'ceiling', 'road, route', 'bed ', 'windowpane, window ', 'grass', 'cabinet', 'sidewalk, pavement', 'person, individual, someone, somebody, mortal, soul', 'earth, ground', 'door, double door', 'table', 'mountain, mount', 'plant, flora, plant life', 'curtain, drape, drapery, mantle, pall', 'chair', 'car, auto, automobile, machine, motorcar', 'water', 'painting, picture', 'sofa, couch, lounge', 'shelf', 'house', 'sea', 'mirror', 'rug, carpet, carpeting', 'field', 'armchair', 'seat', 'fence, fencing', 'desk', 'rock, stone', 'wardrobe, closet, press', 'lamp', 'bathtub, bathing tub, bath, tub', 'railing, rail', 'cushion', 'base, pedestal, stand', 'box', 'column, pillar', 'signboard, sign', 'chest of drawers, chest, bureau, dresser', 'counter', 'sand', 'sink', 'skyscraper', 'fireplace, hearth, open fireplace', 'refrigerator, icebox', 'grandstand, covered stand', 'path', 'stairs, steps', 'runway', 'case, display case, showcase, vitrine', 'pool table, billiard table, snooker table', 'pillow', 'screen door, screen', 'stairway, staircase', 'river', 'bridge, span', 'bookcase', 'blind, screen', 'coffee table, cocktail table', 'toilet, can, commode, crapper, pot, potty, stool, throne', 'flower', 'book', 'hill', 'bench', 'countertop', 'stove, kitchen stove, range, kitchen range, cooking stove', 'palm, palm tree', 'kitchen island', 'computer, computing machine, computing device, data processor, electronic computer, information processing system', 'swivel chair', 'boat', 'bar', 'arcade machine', 'hovel, hut, hutch, shack, shanty', 'bus, autobus, coach, charabanc, double-decker, jitney, motorbus, motorcoach, omnibus, passenger vehicle', 'towel', 'light, light source', 'truck, motortruck', 'tower', 'chandelier, pendant, pendent', 'awning, sunshade, sunblind', 'streetlight, street lamp', 'booth, cubicle, stall, kiosk', 'television, television receiver, television set, tv, tv set, idiot box, boob tube, telly, goggle box', 'airplane, aeroplane, plane', 'dirt track', 'apparel, wearing apparel, dress, clothes', 'pole', 'land, ground, soil', 'bannister, banister, balustrade, balusters, handrail', 'escalator, moving staircase, moving stairway', 'ottoman, pouf, pouffe, puff, hassock', 'bottle', 'buffet, counter, sideboard', 'poster, posting, placard, notice, bill, card', 'stage', 'van', 'ship', 'fountain', 'conveyer belt, conveyor belt, conveyer, conveyor, transporter', 'canopy', 'washer, automatic washer, washing machine', 'plaything, toy', 'swimming pool, swimming bath, natatorium', 'stool', 'barrel, cask', 'basket, handbasket', 'waterfall, falls', 'tent, collapsible shelter', 'bag', 'minibike, motorbike', 'cradle', 'oven', 'ball', 'food, solid food', 'step, stair', 'tank, storage tank', 'trade name, brand name, brand, marque', 'microwave, microwave oven', 'pot, flowerpot', 'animal, animate being, beast, brute, creature, fauna', 'bicycle, bike, wheel, cycle ', 'lake', 'dishwasher, dish washer, dishwashing machine', 'screen, silver screen, projection screen', 'blanket, cover', 'sculpture', 'hood, exhaust hood', 'sconce', 'vase', 'traffic light, traffic signal, stoplight', 'tray', 'ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin', 'fan', 'pier, wharf, wharfage, dock', 'crt screen', 'plate', 'monitor, monitoring device', 'bulletin board, notice board', 'shower', 'radiator', 'glass, drinking glass', 'clock', 'flag', '']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZS3BUfNPKdM","executionInfo":{"status":"ok","timestamp":1628705622626,"user_tz":-120,"elapsed":10,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"732762da-1793-44e3-862d-e379e52bf51b"},"source":["import json\n","from numpy import loadtxt\n","\n","labels_json = {\"labels\": labels_list}\n","\n","# load the model\n","mlmodel = ct.models.MLModel(spec)\n","mlmodel.user_defined_metadata[\"com.apple.coreml.model.preview.type\"] = \"imageSegmenter\"\n","mlmodel.user_defined_metadata['com.apple.coreml.model.preview.params'] = json.dumps(labels_json)\n","\n","mlmodel.save(\"DeepLabV3_ADE20K.mlmodel\")\n","print(mlmodel)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["input {\n","  name: \"image\"\n","  shortDescription: \"Input image\"\n","  type {\n","    imageType {\n","      width: 513\n","      height: 513\n","      colorSpace: RGB\n","    }\n","  }\n","}\n","output {\n","  name: \"scores\"\n","  shortDescription: \"Segmentation map\"\n","  type {\n","    multiArrayType {\n","      shape: 513\n","      shape: 513\n","      dataType: INT32\n","    }\n","  }\n","}\n","metadata {\n","  shortDescription: \"deeplabv3_mnv2_ade20k_train_2018_12_03\"\n","  versionString: \"2021-08-11\"\n","  author: \"Converted by Anh\"\n","  userDefined {\n","    key: \"com.apple.coreml.model.preview.params\"\n","    value: \"{\\\"labels\\\": [\\\"\\\", \\\"wall\\\", \\\"building, edifice\\\", \\\"sky\\\", \\\"floor, flooring\\\", \\\"tree\\\", \\\"ceiling\\\", \\\"road, route\\\", \\\"bed \\\", \\\"windowpane, window \\\", \\\"grass\\\", \\\"cabinet\\\", \\\"sidewalk, pavement\\\", \\\"person, individual, someone, somebody, mortal, soul\\\", \\\"earth, ground\\\", \\\"door, double door\\\", \\\"table\\\", \\\"mountain, mount\\\", \\\"plant, flora, plant life\\\", \\\"curtain, drape, drapery, mantle, pall\\\", \\\"chair\\\", \\\"car, auto, automobile, machine, motorcar\\\", \\\"water\\\", \\\"painting, picture\\\", \\\"sofa, couch, lounge\\\", \\\"shelf\\\", \\\"house\\\", \\\"sea\\\", \\\"mirror\\\", \\\"rug, carpet, carpeting\\\", \\\"field\\\", \\\"armchair\\\", \\\"seat\\\", \\\"fence, fencing\\\", \\\"desk\\\", \\\"rock, stone\\\", \\\"wardrobe, closet, press\\\", \\\"lamp\\\", \\\"bathtub, bathing tub, bath, tub\\\", \\\"railing, rail\\\", \\\"cushion\\\", \\\"base, pedestal, stand\\\", \\\"box\\\", \\\"column, pillar\\\", \\\"signboard, sign\\\", \\\"chest of drawers, chest, bureau, dresser\\\", \\\"counter\\\", \\\"sand\\\", \\\"sink\\\", \\\"skyscraper\\\", \\\"fireplace, hearth, open fireplace\\\", \\\"refrigerator, icebox\\\", \\\"grandstand, covered stand\\\", \\\"path\\\", \\\"stairs, steps\\\", \\\"runway\\\", \\\"case, display case, showcase, vitrine\\\", \\\"pool table, billiard table, snooker table\\\", \\\"pillow\\\", \\\"screen door, screen\\\", \\\"stairway, staircase\\\", \\\"river\\\", \\\"bridge, span\\\", \\\"bookcase\\\", \\\"blind, screen\\\", \\\"coffee table, cocktail table\\\", \\\"toilet, can, commode, crapper, pot, potty, stool, throne\\\", \\\"flower\\\", \\\"book\\\", \\\"hill\\\", \\\"bench\\\", \\\"countertop\\\", \\\"stove, kitchen stove, range, kitchen range, cooking stove\\\", \\\"palm, palm tree\\\", \\\"kitchen island\\\", \\\"computer, computing machine, computing device, data processor, electronic computer, information processing system\\\", \\\"swivel chair\\\", \\\"boat\\\", \\\"bar\\\", \\\"arcade machine\\\", \\\"hovel, hut, hutch, shack, shanty\\\", \\\"bus, autobus, coach, charabanc, double-decker, jitney, motorbus, motorcoach, omnibus, passenger vehicle\\\", \\\"towel\\\", \\\"light, light source\\\", \\\"truck, motortruck\\\", \\\"tower\\\", \\\"chandelier, pendant, pendent\\\", \\\"awning, sunshade, sunblind\\\", \\\"streetlight, street lamp\\\", \\\"booth, cubicle, stall, kiosk\\\", \\\"television, television receiver, television set, tv, tv set, idiot box, boob tube, telly, goggle box\\\", \\\"airplane, aeroplane, plane\\\", \\\"dirt track\\\", \\\"apparel, wearing apparel, dress, clothes\\\", \\\"pole\\\", \\\"land, ground, soil\\\", \\\"bannister, banister, balustrade, balusters, handrail\\\", \\\"escalator, moving staircase, moving stairway\\\", \\\"ottoman, pouf, pouffe, puff, hassock\\\", \\\"bottle\\\", \\\"buffet, counter, sideboard\\\", \\\"poster, posting, placard, notice, bill, card\\\", \\\"stage\\\", \\\"van\\\", \\\"ship\\\", \\\"fountain\\\", \\\"conveyer belt, conveyor belt, conveyer, conveyor, transporter\\\", \\\"canopy\\\", \\\"washer, automatic washer, washing machine\\\", \\\"plaything, toy\\\", \\\"swimming pool, swimming bath, natatorium\\\", \\\"stool\\\", \\\"barrel, cask\\\", \\\"basket, handbasket\\\", \\\"waterfall, falls\\\", \\\"tent, collapsible shelter\\\", \\\"bag\\\", \\\"minibike, motorbike\\\", \\\"cradle\\\", \\\"oven\\\", \\\"ball\\\", \\\"food, solid food\\\", \\\"step, stair\\\", \\\"tank, storage tank\\\", \\\"trade name, brand name, brand, marque\\\", \\\"microwave, microwave oven\\\", \\\"pot, flowerpot\\\", \\\"animal, animate being, beast, brute, creature, fauna\\\", \\\"bicycle, bike, wheel, cycle \\\", \\\"lake\\\", \\\"dishwasher, dish washer, dishwashing machine\\\", \\\"screen, silver screen, projection screen\\\", \\\"blanket, cover\\\", \\\"sculpture\\\", \\\"hood, exhaust hood\\\", \\\"sconce\\\", \\\"vase\\\", \\\"traffic light, traffic signal, stoplight\\\", \\\"tray\\\", \\\"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\\\", \\\"fan\\\", \\\"pier, wharf, wharfage, dock\\\", \\\"crt screen\\\", \\\"plate\\\", \\\"monitor, monitoring device\\\", \\\"bulletin board, notice board\\\", \\\"shower\\\", \\\"radiator\\\", \\\"glass, drinking glass\\\", \\\"clock\\\", \\\"flag\\\", \\\"\\\"]}\"\n","  }\n","  userDefined {\n","    key: \"com.apple.coreml.model.preview.type\"\n","    value: \"imageSegmenter\"\n","  }\n","  userDefined {\n","    key: \"com.github.apple.coremltools.source\"\n","    value: \"tensorflow==1.15.2\"\n","  }\n","  userDefined {\n","    key: \"com.github.apple.coremltools.version\"\n","    value: \"4.1\"\n","  }\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8I-WUAepVSmF","executionInfo":{"status":"ok","timestamp":1628705622627,"user_tz":-120,"elapsed":3,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}}},"source":[""],"execution_count":16,"outputs":[]}]}