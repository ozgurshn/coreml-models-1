{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SSDMobileNetV2_CoreML_trial6.ipynb","provenance":[{"file_id":"1STBtUWfpQsxwpRxJQdFkpy-EuFW7RLLB","timestamp":1628754128783},{"file_id":"11YlmUU9YWApv_uusmFUBVx7Fzw0YmtBE","timestamp":1628341373042}],"collapsed_sections":[],"authorship_tag":"ABX9TyNQlL9IwCREDa4eheRDvn3c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hVLlBO4Vv29c"},"source":["# About\n","\n","Convert ssd_mobilenet_v2_coco_2018_03_29 to Core ML\n","\n","The code is based on this: https://github.com/hollance/coreml-survival-guide/blob/master/MobileNetV2%2BSSDLite/ssdlite.py\n","\n","\n","\n","Instead of using tfcoreml to convert from TF to Core ML. We use coremltools for conversion. The model is converted successful, but predict too many bounding boxes.\n"]},{"cell_type":"markdown","metadata":{"id":"hBXB3PGJWK_6"},"source":["# Download model and setup environment"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TV1jVg9sUwJn","executionInfo":{"status":"ok","timestamp":1628754197292,"user_tz":-120,"elapsed":4097,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"74c028f5-0676-41e4-a7e9-b0cf4eae0e33"},"source":["!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n","!tar -zxvf ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n","!wget https://raw.githubusercontent.com/hollance/coreml-survival-guide/master/MobileNetV2%2BSSDLite/coco_labels.txt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2021-08-12 07:43:13--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.152.128, 2607:f8b0:4001:c56::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.152.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 187925923 (179M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_coco_2018_03_29.tar.gz’\n","\n","ssd_mobilenet_v2_co 100%[===================>] 179.22M   243MB/s    in 0.7s    \n","\n","2021-08-12 07:43:14 (243 MB/s) - ‘ssd_mobilenet_v2_coco_2018_03_29.tar.gz’ saved [187925923/187925923]\n","\n","ssd_mobilenet_v2_coco_2018_03_29/checkpoint\n","ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.meta\n","ssd_mobilenet_v2_coco_2018_03_29/pipeline.config\n","ssd_mobilenet_v2_coco_2018_03_29/saved_model/saved_model.pb\n","ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb\n","ssd_mobilenet_v2_coco_2018_03_29/saved_model/\n","ssd_mobilenet_v2_coco_2018_03_29/saved_model/variables/\n","ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.index\n","ssd_mobilenet_v2_coco_2018_03_29/\n","ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.data-00000-of-00001\n","--2021-08-12 07:43:16--  https://raw.githubusercontent.com/hollance/coreml-survival-guide/master/MobileNetV2%2BSSDLite/coco_labels.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 641 [text/plain]\n","Saving to: ‘coco_labels.txt’\n","\n","coco_labels.txt     100%[===================>]     641  --.-KB/s    in 0s      \n","\n","2021-08-12 07:43:17 (30.8 MB/s) - ‘coco_labels.txt’ saved [641/641]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSiATHlJRX1y","executionInfo":{"status":"ok","timestamp":1628754208857,"user_tz":-120,"elapsed":7186,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"8f1fc6b0-5d47-46a0-bdda-b41a74b21cb5"},"source":["!pip install coremltools==4.1"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting coremltools==4.1\n","  Downloading coremltools-4.1-cp37-none-manylinux1_x86_64.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<1.20,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.19.5)\n","Collecting attr\n","  Downloading attr-0.3.1.tar.gz (1.7 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (21.0)\n","Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (3.17.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (4.41.1)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (21.2.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.7.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools==4.1) (2.4.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools==4.1) (1.2.1)\n","Building wheels for collected packages: attr\n","  Building wheel for attr (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for attr: filename=attr-0.3.1-py3-none-any.whl size=2457 sha256=cc312b020c2984c41acf4313469d8d6fe9de312846562b28ed07612cc938e1e5\n","  Stored in directory: /root/.cache/pip/wheels/3b/5d/58/41fbe92f47031641008bd8559ee89e58bf0f123f9c18dea1cb\n","Successfully built attr\n","Installing collected packages: attr, coremltools\n","Successfully installed attr-0.3.1 coremltools-4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnB6qS6KfvJy","executionInfo":{"status":"ok","timestamp":1628754318568,"user_tz":-120,"elapsed":7094,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"0cc30f16-b9bd-409b-b50e-0efea907ccf4"},"source":["%tensorflow_version 1.x\n","\n","import sys\n","print(sys.version)\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","import coremltools as ct\n","print(ct.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","3.7.11 (default, Jul  3 2021, 18:01:19) \n","[GCC 7.5.0]\n","1.15.2\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:scikit-learn version 0.22.2.post1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n","WARNING:root:TensorFlow version 1.15.2 detected. Last version known to be fully compatible is 1.15.0 .\n","WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"],"name":"stderr"},{"output_type":"stream","text":["4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"377AE3azWU67"},"source":["# Convert to Core ML"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wE5ZrOAyR1gE","executionInfo":{"status":"ok","timestamp":1628754903511,"user_tz":-120,"elapsed":2141,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"e525b74a-e52e-44d9-bce2-9ef3f4bd4dcb"},"source":["import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.python.tools import strip_unused_lib\n","from tensorflow.python.framework import dtypes\n","from tensorflow.python.platform import gfile\n","\n","\n","# From where to load the saved_model.pb file.\n","saved_model_path = \"ssd_mobilenet_v2_coco_2018_03_29/saved_model\"\n","\n","# Where to save the final Core ML model file.\n","coreml_model_path = \"SSDMobileNetV2.mlmodel\"\n","\n","# The number of predicted classes, excluding background.\n","num_classes = 90\n","\n","# The number of predicted bounding boxes.\n","num_anchors = 1917\n","\n","num_coordinates = 4\n","\n","# Size of the expected input image.\n","input_width = 300\n","input_height = 300\n","\n","\n","# Temporary file. You can delete this after the conversion is done.\n","frozen_model_file = \"frozen_model.pb\"\n","\n","# Names of the interesting tensors in the graph. We use \"Postprocessor/convert_scores\"\n","# instead of \"concat_1\" because this already applies the sigmoid to the class scores.\n","input_name_image = \"Preprocessor/sub\"\n","output_name_box = \"concat\"\n","output_name_score = \"Postprocessor/convert_scores\"\n","\n","\n","def load_saved_model(path):\n","    \"\"\"Loads a saved model into a graph.\"\"\"\n","    print(\"Loading saved_model.pb from '%s'\" % path)\n","    the_graph = tf.Graph()\n","    with tf.Session(graph=the_graph) as sess:\n","        tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], path)\n","    return the_graph\n","\n","\n","def optimize_graph(graph):\n","    \"\"\"Strips unused subgraphs and save it as another frozen TF model.\"\"\"\n","    gdef = strip_unused_lib.strip_unused(\n","            input_graph_def = graph.as_graph_def(),\n","            input_node_names = [input_node],\n","            output_node_names = [bbox_output_node, class_output_node],\n","            placeholder_type_enum = dtypes.float32.as_datatype_enum)\n","\n","    with gfile.GFile(frozen_model_file, \"wb\") as f:\n","        f.write(gdef.SerializeToString())\n","\n","\n","# Load the original graph and remove anything we don't need.\n","the_graph = load_saved_model(saved_model_path)\n","optimize_graph(the_graph)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Loading saved_model.pb from 'ssd_mobilenet_v2_coco_2018_03_29/saved_model'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"koPoR05mU1dJ","executionInfo":{"status":"ok","timestamp":1628755030767,"user_tz":-120,"elapsed":10236,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"b78e24ee-7fd3-47bf-a8e6-05681911f626"},"source":["# ================================\n","# PART 1: Convert the SSD to Core ML\n","# ================================\n","\n","image_input = ct.ImageType(name=input_name_image,\n","                           shape=(1, input_width, input_height, 3),\n","                           bias=[-1,-1,-1], scale=2./255)\n","\n","ssd_model = ct.convert(\n","    frozen_model_file,\n","    source='tensorflow',\n","    inputs=[image_input],\n","    outputs=[output_name_score, output_name_box]  # the order in list is important\n",")\n","\n","print(ssd_model)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Running TensorFlow Graph Passes: 100%|██████████| 7/7 [00:00<00:00, 10.22 passes/s]\n","Converting Frontend ==> MIL Ops: 100%|██████████| 666/666 [00:01<00:00, 461.97 ops/s]\n","Running MIL optimization passes: 100%|██████████| 18/18 [00:02<00:00,  8.19 passes/s]\n","Translating MIL ==> MLModel Ops: 100%|██████████| 1052/1052 [00:02<00:00, 409.19 ops/s]\n"],"name":"stderr"},{"output_type":"stream","text":["input {\n","  name: \"Preprocessor/sub\"\n","  type {\n","    imageType {\n","      width: 300\n","      height: 300\n","      colorSpace: RGB\n","    }\n","  }\n","}\n","output {\n","  name: \"Postprocessor/convert_scores\"\n","  type {\n","    multiArrayType {\n","      dataType: FLOAT32\n","    }\n","  }\n","}\n","output {\n","  name: \"concat\"\n","  type {\n","    multiArrayType {\n","      dataType: FLOAT32\n","    }\n","  }\n","}\n","metadata {\n","  userDefined {\n","    key: \"com.github.apple.coremltools.source\"\n","    value: \"tensorflow==1.15.2\"\n","  }\n","  userDefined {\n","    key: \"com.github.apple.coremltools.version\"\n","    value: \"4.1\"\n","  }\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6tL3R2LDVuqW","executionInfo":{"status":"ok","timestamp":1628755031873,"user_tz":-120,"elapsed":1126,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"30fd922d-01e9-4a11-aa13-418793a34c6e"},"source":["# add missing shape information\n","\n","ssd_model.input_description[input_name_image] = \"Input image to be detected\"\n","ssd_model.output_description[output_name_score] = \"Confidence derived for each of the bounding boxes.\"\n","ssd_model.output_description[output_name_box] = \"Bounding boxes coordinates\"\n","\n","ssd_spec = ssd_model.get_spec()\n","ct.utils.rename_feature(ssd_spec, input_name_image, \"image\")\n","ct.utils.rename_feature(ssd_spec, output_name_score, \"scores\")\n","ct.utils.rename_feature(ssd_spec, output_name_box, \"boxes\")\n","\n","# scores\n","ssd_spec.description.output[0].type.multiArrayType.shape.append(num_classes + 1)\n","ssd_spec.description.output[0].type.multiArrayType.shape.append(num_anchors)\n","\n","# boxes\n","ssd_spec.description.output[1].type.multiArrayType.shape.append(num_coordinates)\n","ssd_spec.description.output[1].type.multiArrayType.shape.append(num_anchors)\n","\n","ssd_spec.description.output[0].type.multiArrayType.dataType = ct.proto.FeatureTypes_pb2.ArrayFeatureType.DOUBLE\n","ssd_spec.description.output[1].type.multiArrayType.dataType = ct.proto.FeatureTypes_pb2.ArrayFeatureType.DOUBLE\n","\n","\n","ssd_model = ct.models.MLModel(ssd_spec)\n","ssd_model.save(\"SSD.mlmodel\")\n","\n","print(ssd_model)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["input {\n","  name: \"image\"\n","  shortDescription: \"Input image to be detected\"\n","  type {\n","    imageType {\n","      width: 300\n","      height: 300\n","      colorSpace: RGB\n","    }\n","  }\n","}\n","output {\n","  name: \"scores\"\n","  shortDescription: \"Confidence derived for each of the bounding boxes.\"\n","  type {\n","    multiArrayType {\n","      shape: 91\n","      shape: 1917\n","      dataType: DOUBLE\n","    }\n","  }\n","}\n","output {\n","  name: \"boxes\"\n","  shortDescription: \"Bounding boxes coordinates\"\n","  type {\n","    multiArrayType {\n","      shape: 4\n","      shape: 1917\n","      dataType: DOUBLE\n","    }\n","  }\n","}\n","metadata {\n","  userDefined {\n","    key: \"com.github.apple.coremltools.source\"\n","    value: \"tensorflow==1.15.2\"\n","  }\n","  userDefined {\n","    key: \"com.github.apple.coremltools.version\"\n","    value: \"4.1\"\n","  }\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4u-vqzuVNmJ","executionInfo":{"status":"ok","timestamp":1628755060711,"user_tz":-120,"elapsed":843,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"5a94ea4b-78dc-44f3-c6d2-48b6b8d25e1e"},"source":["# ================================\n","# PART 2: Decoding the coordinates\n","# ================================\n","\n","def get_anchors(graph, tensor_name):\n","    \"\"\"\n","    Computes the list of anchor boxes by sending a fake image through the graph.\n","    Outputs an array of size (4, num_anchors) where each element is an anchor box\n","    given as [ycenter, xcenter, height, width] in normalized coordinates.\n","    \"\"\"\n","    image_tensor = graph.get_tensor_by_name(\"image_tensor:0\")\n","    box_corners_tensor = graph.get_tensor_by_name(tensor_name)\n","    box_corners = sess.run(box_corners_tensor, feed_dict={image_tensor: np.zeros((1, input_height, input_width, 3))})\n","\n","    # The TensorFlow graph gives each anchor box as [ymin, xmin, ymax, xmax]. \n","    # Convert these min/max values to a center coordinate, width and height.\n","    ymin, xmin, ymax, xmax = np.transpose(box_corners)\n","    width = xmax - xmin\n","    height = ymax - ymin\n","    ycenter = ymin + height / 2.\n","    xcenter = xmin + width / 2.\n","    return np.stack([ycenter, xcenter, height, width])\n","\n","\n","# Read the anchors into a (4, 1917) tensor.\n","anchors_tensor = \"Concatenate/concat:0\"\n","with the_graph.as_default():\n","    with tf.Session(graph=the_graph) as sess:\n","        anchors = get_anchors(the_graph, anchors_tensor)\n","        assert(anchors.shape[1] == num_anchors)\n","\n","\n","from coremltools.models import datatypes\n","from coremltools.models import neural_network\n","\n","# MLMultiArray inputs of neural networks must have 1 or 3 dimensions. \n","# We only have 2, so add an unused dimension of size one at the back.\n","input_features = [ (\"scores\", datatypes.Array(num_classes + 1, num_anchors, 1)),\n","                   (\"boxes\", datatypes.Array(4, num_anchors, 1)) ]\n","\n","# The outputs of the decoder model should match the inputs of the next\n","# model in the pipeline, NonMaximumSuppression. This expects the number\n","# of bounding boxes in the first dimension.\n","output_features = [ (\"raw_confidence\", datatypes.Array(num_anchors, num_classes)),\n","                    (\"raw_coordinates\", datatypes.Array(num_anchors, 4)) ]\n","\n","builder = neural_network.NeuralNetworkBuilder(input_features, output_features)\n","\n","# (num_classes+1, num_anchors, 1) --> (1, num_anchors, num_classes+1)\n","builder.add_permute(name=\"permute_scores\",\n","                    dim=(0, 3, 2, 1),\n","                    input_name=\"scores\",\n","                    output_name=\"permute_scores_output\")\n","\n","# Strip off the \"unknown\" class (at index 0).\n","builder.add_slice(name=\"slice_scores\",\n","                  input_name=\"permute_scores_output\",\n","                  output_name=\"raw_confidence\",\n","                  axis=\"width\",\n","                  start_index=1,\n","                  end_index=num_classes + 1)\n","\n","# Grab the y, x coordinates (channels 0-1).\n","builder.add_slice(name=\"slice_yx\",\n","                  input_name=\"boxes\",\n","                  output_name=\"slice_yx_output\",\n","                  axis=\"channel\",\n","                  start_index=0,\n","                  end_index=2)\n","\n","# boxes_yx / 10\n","builder.add_elementwise(name=\"scale_yx\",\n","                        input_names=\"slice_yx_output\",\n","                        output_name=\"scale_yx_output\",\n","                        mode=\"MULTIPLY\",\n","                        alpha=0.1)\n","\n","# Split the anchors into two (2, 1917, 1) arrays.\n","anchors_yx = np.expand_dims(anchors[:2, :], axis=-1)\n","anchors_hw = np.expand_dims(anchors[2:, :], axis=-1)\n","\n","builder.add_load_constant(name=\"anchors_yx\",\n","                          output_name=\"anchors_yx\",\n","                          constant_value=anchors_yx,\n","                          shape=[2, num_anchors, 1])\n","\n","builder.add_load_constant(name=\"anchors_hw\",\n","                          output_name=\"anchors_hw\",\n","                          constant_value=anchors_hw,\n","                          shape=[2, num_anchors, 1])\n","\n","# (boxes_yx / 10) * anchors_hw\n","builder.add_elementwise(name=\"yw_times_hw\",\n","                        input_names=[\"scale_yx_output\", \"anchors_hw\"],\n","                        output_name=\"yw_times_hw_output\",\n","                        mode=\"MULTIPLY\")\n","\n","# (boxes_yx / 10) * anchors_hw + anchors_yx\n","builder.add_elementwise(name=\"decoded_yx\",\n","                        input_names=[\"yw_times_hw_output\", \"anchors_yx\"],\n","                        output_name=\"decoded_yx_output\",\n","                        mode=\"ADD\")\n","\n","# Grab the height and width (channels 2-3).\n","builder.add_slice(name=\"slice_hw\",\n","                  input_name=\"boxes\",\n","                  output_name=\"slice_hw_output\",\n","                  axis=\"channel\",\n","                  start_index=2,\n","                  end_index=4)\n","\n","# (boxes_hw / 5)\n","builder.add_elementwise(name=\"scale_hw\",\n","                        input_names=\"slice_hw_output\",\n","                        output_name=\"scale_hw_output\",\n","                        mode=\"MULTIPLY\",\n","                        alpha=0.2)\n","\n","# exp(boxes_hw / 5)\n","builder.add_unary(name=\"exp_hw\",\n","                  input_name=\"scale_hw_output\",\n","                  output_name=\"exp_hw_output\",\n","                  mode=\"exp\")\n","\n","# exp(boxes_hw / 5) * anchors_hw\n","builder.add_elementwise(name=\"decoded_hw\",\n","                        input_names=[\"exp_hw_output\", \"anchors_hw\"],\n","                        output_name=\"decoded_hw_output\",\n","                        mode=\"MULTIPLY\")\n","\n","# The coordinates are now (y, x) and (height, width) but NonMaximumSuppression\n","# wants them as (x, y, width, height). So create four slices and then concat\n","# them into the right order.\n","builder.add_slice(name=\"slice_y\",\n","                  input_name=\"decoded_yx_output\",\n","                  output_name=\"slice_y_output\",\n","                  axis=\"channel\",\n","                  start_index=0,\n","                  end_index=1)\n","\n","builder.add_slice(name=\"slice_x\",\n","                  input_name=\"decoded_yx_output\",\n","                  output_name=\"slice_x_output\",\n","                  axis=\"channel\",\n","                  start_index=1,\n","                  end_index=2)\n","\n","builder.add_slice(name=\"slice_h\",\n","                  input_name=\"decoded_hw_output\",\n","                  output_name=\"slice_h_output\",\n","                  axis=\"channel\",\n","                  start_index=0,\n","                  end_index=1)\n","\n","builder.add_slice(name=\"slice_w\",\n","                  input_name=\"decoded_hw_output\",\n","                  output_name=\"slice_w_output\",\n","                  axis=\"channel\",\n","                  start_index=1,\n","                  end_index=2)\n","\n","builder.add_elementwise(name=\"concat\",\n","                        input_names=[\"slice_x_output\", \"slice_y_output\", \n","                                     \"slice_w_output\", \"slice_h_output\"],\n","                        output_name=\"concat_output\",\n","                        mode=\"CONCAT\")\n","\n","# (4, num_anchors, 1) --> (1, num_anchors, 4)\n","builder.add_permute(name=\"permute_output\",\n","                    dim=(0, 3, 2, 1),\n","                    input_name=\"concat_output\",\n","                    output_name=\"raw_coordinates\")\n","\n","decoder_model = ct.models.MLModel(builder.spec)\n","decoder_model.save(\"Decoder.mlmodel\")\n","\n","print(decoder_model)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["input {\n","  name: \"scores\"\n","  type {\n","    multiArrayType {\n","      shape: 91\n","      shape: 1917\n","      shape: 1\n","      dataType: DOUBLE\n","    }\n","  }\n","}\n","input {\n","  name: \"boxes\"\n","  type {\n","    multiArrayType {\n","      shape: 4\n","      shape: 1917\n","      shape: 1\n","      dataType: DOUBLE\n","    }\n","  }\n","}\n","output {\n","  name: \"raw_confidence\"\n","  type {\n","    multiArrayType {\n","      shape: 1917\n","      shape: 90\n","      dataType: DOUBLE\n","    }\n","  }\n","}\n","output {\n","  name: \"raw_coordinates\"\n","  type {\n","    multiArrayType {\n","      shape: 1917\n","      shape: 4\n","      dataType: DOUBLE\n","    }\n","  }\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PUykDbl7VVZ3","executionInfo":{"status":"ok","timestamp":1628755066572,"user_tz":-120,"elapsed":205,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"41fb7d4f-e577-48c5-a9d9-7068acff8111"},"source":["# ===============================\n","# PART 3: Non-maximum suppression\n","# ===============================\n","\n","nms_spec = ct.proto.Model_pb2.Model()\n","nms_spec.specificationVersion = 3\n","\n","for i in range(2):\n","    decoder_output = decoder_model._spec.description.output[i].SerializeToString()\n","\n","    nms_spec.description.input.add()\n","    nms_spec.description.input[i].ParseFromString(decoder_output)\n","\n","    nms_spec.description.output.add()\n","    nms_spec.description.output[i].ParseFromString(decoder_output)\n","    \n","nms_spec.description.output[0].name = \"confidence\"\n","nms_spec.description.output[1].name = \"coordinates\"\n","\n","output_sizes = [num_classes, 4]\n","for i in range(2):\n","    ma_type = nms_spec.description.output[i].type.multiArrayType\n","    ma_type.shapeRange.sizeRanges.add()\n","    ma_type.shapeRange.sizeRanges[0].lowerBound = 0\n","    ma_type.shapeRange.sizeRanges[0].upperBound = -1\n","    ma_type.shapeRange.sizeRanges.add()\n","    ma_type.shapeRange.sizeRanges[1].lowerBound = output_sizes[i]\n","    ma_type.shapeRange.sizeRanges[1].upperBound = output_sizes[i]\n","    del ma_type.shape[:]\n","\n","nms = nms_spec.nonMaximumSuppression\n","nms.confidenceInputFeatureName = \"raw_confidence\"\n","nms.coordinatesInputFeatureName = \"raw_coordinates\"\n","nms.confidenceOutputFeatureName = \"confidence\"\n","nms.coordinatesOutputFeatureName = \"coordinates\"\n","nms.iouThresholdInputFeatureName = \"iouThreshold\"\n","nms.confidenceThresholdInputFeatureName = \"confidenceThreshold\"\n","\n","default_iou_threshold = 0.6\n","default_confidence_threshold = 0.4\n","nms.iouThreshold = default_iou_threshold\n","nms.confidenceThreshold = default_confidence_threshold\n","\n","nms.pickTop.perClass = True\n","\n","labels = np.loadtxt(\"coco_labels.txt\", dtype=str, delimiter=\"\\n\")\n","nms.stringClassLabels.vector.extend(labels)\n","\n","nms_model = ct.models.MLModel(nms_spec)\n","nms_model.save(\"NMS.mlmodel\")\n","\n","print(nms_model)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["input {\n","  name: \"raw_confidence\"\n","  type {\n","    multiArrayType {\n","      shape: 1917\n","      shape: 90\n","      dataType: DOUBLE\n","    }\n","  }\n","}\n","input {\n","  name: \"raw_coordinates\"\n","  type {\n","    multiArrayType {\n","      shape: 1917\n","      shape: 4\n","      dataType: DOUBLE\n","    }\n","  }\n","}\n","output {\n","  name: \"confidence\"\n","  type {\n","    multiArrayType {\n","      dataType: DOUBLE\n","      shapeRange {\n","        sizeRanges {\n","          upperBound: -1\n","        }\n","        sizeRanges {\n","          lowerBound: 90\n","          upperBound: 90\n","        }\n","      }\n","    }\n","  }\n","}\n","output {\n","  name: \"coordinates\"\n","  type {\n","    multiArrayType {\n","      dataType: DOUBLE\n","      shapeRange {\n","        sizeRanges {\n","          upperBound: -1\n","        }\n","        sizeRanges {\n","          lowerBound: 4\n","          upperBound: 4\n","        }\n","      }\n","    }\n","  }\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0vs96woVble","executionInfo":{"status":"ok","timestamp":1628755068417,"user_tz":-120,"elapsed":1008,"user":{"displayName":"Anh Nguyen","photoUrl":"","userId":"01617909942388387911"}},"outputId":"ab9c0f52-1819-472a-b0b4-93d1d8a7e9cb"},"source":["# ===============================================\n","# PART 4: Putting it all together into a pipeline\n","# ===============================================\n","\n","from coremltools.models.pipeline import *\n","\n","input_features = [ (\"image\", datatypes.Array(3, 300, 300)),\n","                   (\"iouThreshold\", datatypes.Double()),\n","                   (\"confidenceThreshold\", datatypes.Double()) ]\n","\n","output_features = [ \"confidence\", \"coordinates\" ]\n","\n","pipeline = Pipeline(input_features, output_features)\n","\n","# We added a dimension of size 1 to the back of the inputs of the decoder \n","# model, so we should also add this to the output of the SSD model or else \n","# the inputs and outputs do not match and the pipeline is not valid.\n","ssd_output = ssd_model._spec.description.output\n","ssd_output[0].type.multiArrayType.shape[:] = [num_classes + 1, num_anchors, 1]\n","ssd_output[1].type.multiArrayType.shape[:] = [4, num_anchors, 1]\n","\n","pipeline.add_model(ssd_model)\n","pipeline.add_model(decoder_model)\n","pipeline.add_model(nms_model)\n","\n","# The \"image\" input should really be an image, not a multi-array.\n","pipeline.spec.description.input[0].ParseFromString(ssd_model._spec.description.input[0].SerializeToString())\n","\n","# Copy the declarations of the \"confidence\" and \"coordinates\" outputs.\n","# The Pipeline makes these strings by default.\n","pipeline.spec.description.output[0].ParseFromString(nms_model._spec.description.output[0].SerializeToString())\n","pipeline.spec.description.output[1].ParseFromString(nms_model._spec.description.output[1].SerializeToString())\n","\n","# Add descriptions to the inputs and outputs.\n","pipeline.spec.description.input[1].shortDescription = f\"(optional) IOU Threshold override (default={default_iou_threshold}\"\n","pipeline.spec.description.input[2].shortDescription = f\"(optional) Confidence Threshold override (default={default_confidence_threshold})\"\n","pipeline.spec.description.output[0].shortDescription = u\"Boxes \\xd7 Class confidence\"\n","pipeline.spec.description.output[1].shortDescription = u\"Boxes \\xd7 [x, y, width, height] (relative to image size)\"\n","\n","# Add metadata to the model.\n","pipeline.spec.description.metadata.versionString = \"ssd_mobilenet_v2_coco_2018_03_29\"\n","pipeline.spec.description.metadata.shortDescription = \"\"\"\n","MobileNetV2 + SSD, trained on COCO. Source: http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n","\"\"\"\n","pipeline.spec.description.metadata.author = \"Converted to Core ML by Anh\"\n","pipeline.spec.description.metadata.license = \"https://github.com/tensorflow/models/blob/master/research/object_detection\"\n","\n","# Add the list of class labels and the default threshold values too.\n","user_defined_metadata = {\n","    \"iou_threshold\": str(default_iou_threshold),\n","    \"confidence_threshold\": str(default_confidence_threshold),\n","    \"classes\": \",\".join(labels)\n","}\n","pipeline.spec.description.metadata.userDefined.update(user_defined_metadata)\n","\n","# Don't forget this or Core ML might attempt to run the model on an unsupported\n","# operating system version!\n","pipeline.spec.specificationVersion = 3\n","\n","final_model = ct.models.MLModel(pipeline.spec)\n","final_model.save(coreml_model_path)\n","\n","print(final_model)\n","print(\"Done!\")"],"execution_count":21,"outputs":[{"output_type":"stream","text":["input {\n","  name: \"image\"\n","  shortDescription: \"Input image to be detected\"\n","  type {\n","    imageType {\n","      width: 300\n","      height: 300\n","      colorSpace: RGB\n","    }\n","  }\n","}\n","input {\n","  name: \"iouThreshold\"\n","  shortDescription: \"(optional) IOU Threshold override (default=0.6\"\n","  type {\n","    doubleType {\n","    }\n","  }\n","}\n","input {\n","  name: \"confidenceThreshold\"\n","  shortDescription: \"(optional) Confidence Threshold override (default=0.4)\"\n","  type {\n","    doubleType {\n","    }\n","  }\n","}\n","output {\n","  name: \"confidence\"\n","  shortDescription: \"Boxes \\303\\227 Class confidence\"\n","  type {\n","    multiArrayType {\n","      dataType: DOUBLE\n","      shapeRange {\n","        sizeRanges {\n","          upperBound: -1\n","        }\n","        sizeRanges {\n","          lowerBound: 90\n","          upperBound: 90\n","        }\n","      }\n","    }\n","  }\n","}\n","output {\n","  name: \"coordinates\"\n","  shortDescription: \"Boxes \\303\\227 [x, y, width, height] (relative to image size)\"\n","  type {\n","    multiArrayType {\n","      dataType: DOUBLE\n","      shapeRange {\n","        sizeRanges {\n","          upperBound: -1\n","        }\n","        sizeRanges {\n","          lowerBound: 4\n","          upperBound: 4\n","        }\n","      }\n","    }\n","  }\n","}\n","metadata {\n","  shortDescription: \"\\nMobileNetV2 + SSD, trained on COCO. Source: http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\\n\"\n","  versionString: \"ssd_mobilenet_v2_coco_2018_03_29\"\n","  author: \"Converted to Core ML by Anh\"\n","  license: \"https://github.com/tensorflow/models/blob/master/research/object_detection\"\n","  userDefined {\n","    key: \"classes\"\n","    value: \"person,bicycle,car,motorcycle,airplane,bus,train,truck,boat,traffic light,fire hydrant,?,stop sign,parking meter,bench,bird,cat,dog,horse,sheep,cow,elephant,bear,zebra,giraffe,?,backpack,umbrella,?,?,handbag,tie,suitcase,frisbee,skis,snowboard,sports ball,kite,baseball bat,baseball glove,skateboard,surfboard,tennis racket,bottle,?,wine glass,cup,fork,knife,spoon,bowl,banana,apple,sandwich,orange,broccoli,carrot,hot dog,pizza,donut,cake,chair,couch,potted plant,bed,?,dining table,?,?,toilet,?,tv,laptop,mouse,remote,keyboard,cell phone,microwave,oven,toaster,sink,refrigerator,?,book,clock,vase,scissors,teddy bear,hair drier,toothbrush\"\n","  }\n","  userDefined {\n","    key: \"confidence_threshold\"\n","    value: \"0.4\"\n","  }\n","  userDefined {\n","    key: \"iou_threshold\"\n","    value: \"0.6\"\n","  }\n","}\n","\n","Done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"be5JmS4lWemV"},"source":[""],"execution_count":null,"outputs":[]}]}