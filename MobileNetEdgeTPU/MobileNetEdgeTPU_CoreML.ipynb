{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetEdgeTPU_CoreML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzcgm8g_motn"
      },
      "source": [
        "# About\n",
        "This script is used to convert MobileNet EdgeTPU to Core ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoS44WFvmzl_"
      },
      "source": [
        "# Download model and setup enviroments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTEFW3NKoa1B"
      },
      "source": [
        "Download the TF model from this link:  \n",
        "https://storage.cloud.google.com/mobilenet_edgetpu/checkpoints/mobilenet_edgetpu_224_1.0.tgz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb6BrJnum8Un",
        "outputId": "b3cd8aaa-5725-485e-ff34-042fe40bcbcc"
      },
      "source": [
        "!pip install coremltools==4.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting coremltools==4.1\n",
            "  Downloading coremltools-4.1-cp37-none-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (21.2.0)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (3.17.3)\n",
            "Collecting attr\n",
            "  Downloading attr-0.3.1.tar.gz (1.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.4.1)\n",
            "Requirement already satisfied: numpy<1.20,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools==4.1) (2.4.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools==4.1) (1.2.1)\n",
            "Building wheels for collected packages: attr\n",
            "  Building wheel for attr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for attr: filename=attr-0.3.1-py3-none-any.whl size=2457 sha256=8b992751f96637404a8e95516a6a843b890ac098e046d4c326d4693c21950607\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/5d/58/41fbe92f47031641008bd8559ee89e58bf0f123f9c18dea1cb\n",
            "Successfully built attr\n",
            "Installing collected packages: attr, coremltools\n",
            "Successfully installed attr-0.3.1 coremltools-4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dBs7IpKxR-p"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BlsvWDA5KYD",
        "outputId": "a2ebe46a-c369-4b23-b317-6522da583f0a"
      },
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import coremltools as ct\n",
        "print(ct.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.7.11 (default, Jul  3 2021, 18:01:19) \n",
            "[GCC 7.5.0]\n",
            "2.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:scikit-learn version 0.22.2.post1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
            "WARNING:root:TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
            "WARNING:root:Keras version 2.5.0 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r1g6q-xo5OF"
      },
      "source": [
        "# Convert from TF to Core ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LITfrMmAInvU"
      },
      "source": [
        "from tensorflow.python.tools import strip_unused_lib\n",
        "from tensorflow.python.framework import dtypes\n",
        "from tensorflow.python.platform import gfile\n",
        "\n",
        "from tensorflow.python.saved_model import signature_constants\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "\n",
        "def load_frozen_graph(path):\n",
        "  with tf.io.gfile.GFile(path, \"rb\") as f:\n",
        "    graph_def = tf.compat.v1.GraphDef()\n",
        "    graph_def.ParseFromString(f.read())\n",
        "    return graph_def\n",
        "\n",
        "def optimize_graph(graph_def, \n",
        "                   input_node_name, \n",
        "                   output_node_name,\n",
        "                   export_dir):\n",
        "  gdef = strip_unused_lib.strip_unused(\n",
        "          input_graph_def = graph_def,\n",
        "          input_node_names = [input_node_name],\n",
        "          output_node_names = [output_node_name],\n",
        "          placeholder_type_enum = dtypes.float32.as_datatype_enum)\n",
        "\n",
        "  builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir)\n",
        "  sigs = {}\n",
        "  \n",
        "  with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n",
        "      tf.import_graph_def(gdef, name=\"\")\n",
        "      g = tf.compat.v1.get_default_graph()\n",
        "      input_name = g.get_tensor_by_name(input_node_name+':0')\n",
        "      output_name = g.get_tensor_by_name(output_node_name+':0')\n",
        "\n",
        "      sigs[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = \\\n",
        "        tf.compat.v1.saved_model.signature_def_utils.predict_signature_def(\n",
        "          {\"input\": input_name}, {\"output\": output_name})\n",
        "\n",
        "      builder.add_meta_graph_and_variables(sess, [tag_constants.SERVING], signature_def_map=sigs)\n",
        "      builder.save()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5OeuLZK_KIY"
      },
      "source": [
        "def convert_to_coreml(saved_model_dir,\n",
        "                      input_name,\n",
        "                      output_name,\n",
        "                      coreml_file):\n",
        "  # Download class labels (from a separate file)\n",
        "  import urllib\n",
        "  label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "  class_labels = urllib.request.urlopen(label_url).read().splitlines()\n",
        "  assert len(class_labels) == 1001\n",
        "\n",
        "  # make sure entries of class_labels are strings\n",
        "  for i, label in enumerate(class_labels):\n",
        "    if isinstance(label, bytes):\n",
        "      class_labels[i] = label.decode(\"utf8\")\n",
        "\n",
        "  image_input = ct.ImageType(shape=(1, 224, 224, 3),\n",
        "                             bias=[-1,-1,-1],\n",
        "                             scale=1/127)\n",
        "\n",
        "  # set class labels\n",
        "  classifier_config = ct.ClassifierConfig(class_labels)\n",
        "\n",
        "  # Convert the model using the Unified Conversion API\n",
        "  model = ct.convert(\n",
        "      saved_model_dir,\n",
        "      source='tensorflow', \n",
        "      inputs=[image_input], \n",
        "      classifier_config=classifier_config,\n",
        "  )\n",
        "\n",
        "  print(model.input_description, '->', model.output_description)\n",
        "\n",
        "  # Set feature descriptions (these show up as comments in XCode)\n",
        "  model.input_description[\"images\"] = \"Input image to be classified\"\n",
        "  model.output_description[\"Softmax\"] = \"Most likely image category\"\n",
        "\n",
        "  # Set model author name\n",
        "  model.author = 'Converted from TF to Core ML by Anh'\n",
        "\n",
        "  # Set a short description for the Xcode UI\n",
        "  model.short_description = '''\n",
        "  MobilenetEdgeTPU from \n",
        "  https://storage.cloud.google.com/mobilenet_edgetpu/checkpoints/mobilenet_edgetpu_224_1.0.tgz\n",
        "  '''\n",
        "\n",
        "  # Set a version for the model\n",
        "  model.version = \"2021-07-30\"\n",
        "\n",
        "  spec = model._spec\n",
        "\n",
        "  ct.utils.rename_feature(spec, input_name, \"image\")\n",
        "  ct.utils.rename_feature(spec, output_name, \"classLabelProbs\")\n",
        "\n",
        "  print(model.input_description, '->', model.output_description)\n",
        "\n",
        "  model.save(coreml_file)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSN_sH68-jqv",
        "outputId": "b667b408-ca47-4dd2-88e3-7f117d4ecb15"
      },
      "source": [
        "# Download the model from \n",
        "# https://storage.cloud.google.com/mobilenet_edgetpu/checkpoints/mobilenet_edgetpu_224_1.0.tgz\n",
        "\n",
        "input_name = 'images'\n",
        "output_name = 'Softmax'\n",
        "export_dir = 'optimized_saved_model'\n",
        "graph_def = load_frozen_graph('/content/drive/MyDrive/models/mobilenet_edgetpu_224_1.0/frozen_graph.pb')\n",
        "optimize_graph(graph_def,\n",
        "               input_name,\n",
        "               output_name,\n",
        "               export_dir)\n",
        "\n",
        "convert_to_coreml(export_dir,\n",
        "                  input_name,\n",
        "                  output_name,\n",
        "                  coreml_file='MobilenetEdgeTPU_Anh.mlmodel')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:00<00:00,  7.90 passes/s]\n",
            "Converting Frontend ==> MIL Ops: 100%|██████████| 465/465 [00:01<00:00, 368.31 ops/s]\n",
            "Running MIL optimization passes: 100%|██████████| 18/18 [00:01<00:00, 16.09 passes/s]\n",
            "Translating MIL ==> MLModel Ops: 100%|██████████| 826/826 [00:00<00:00, 1183.09 ops/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Features(images) -> Features(Softmax,classLabel)\n",
            "Features(image) -> Features(classLabelProbs,classLabel)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGYNk_ri4PlQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}