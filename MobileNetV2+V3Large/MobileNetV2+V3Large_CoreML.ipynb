{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV2+V3Large_CoreML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtBFdSSvMji_",
        "outputId": "ed0a793a-622d-46e1-ec87-ab82f34f3061"
      },
      "source": [
        "!pip install coremltools==4.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting coremltools==4.1\n",
            "  Downloading coremltools-4.1-cp37-none-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.7.1)\n",
            "Collecting attr\n",
            "  Downloading attr-0.3.1.tar.gz (1.7 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (21.0)\n",
            "Requirement already satisfied: numpy<1.20,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (4.41.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (21.2.0)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==4.1) (3.17.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools==4.1) (2.4.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools==4.1) (1.2.1)\n",
            "Building wheels for collected packages: attr\n",
            "  Building wheel for attr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for attr: filename=attr-0.3.1-py3-none-any.whl size=2457 sha256=abc8292a8d1715cec112697a5812f116e459b44e8379cc183917f62ed544a9e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/5d/58/41fbe92f47031641008bd8559ee89e58bf0f123f9c18dea1cb\n",
            "Successfully built attr\n",
            "Installing collected packages: attr, coremltools\n",
            "Successfully installed attr-0.3.1 coremltools-4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dBs7IpKxR-p"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BlsvWDA5KYD",
        "outputId": "19d2c744-6548-4496-9714-d25e87d5823d"
      },
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import coremltools as ct\n",
        "print(ct.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.7.11 (default, Jul  3 2021, 18:01:19) \n",
            "[GCC 7.5.0]\n",
            "2.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:scikit-learn version 0.22.2.post1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
            "WARNING:root:TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
            "WARNING:root:Keras version 2.5.0 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5OeuLZK_KIY"
      },
      "source": [
        "def convert(keras_model, \n",
        "            coreml_file,\n",
        "            input_name,\n",
        "            output_name):\n",
        "  \n",
        "  # Download class labels (from a separate file)\n",
        "  import urllib\n",
        "  label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "  class_labels = urllib.request.urlopen(label_url).read().splitlines()\n",
        "  class_labels = class_labels[1:] # remove the first class which is background\n",
        "  assert len(class_labels) == 1000\n",
        "\n",
        "  # make sure entries of class_labels are strings\n",
        "  for i, label in enumerate(class_labels):\n",
        "    if isinstance(label, bytes):\n",
        "      class_labels[i] = label.decode(\"utf8\")\n",
        "\n",
        "  image_input = ct.ImageType(shape=(1, 224, 224, 3),\n",
        "                              bias=[-1,-1,-1],\n",
        "                              scale=1/127)\n",
        "\n",
        "  # set class labels\n",
        "  classifier_config = ct.ClassifierConfig(class_labels)\n",
        "\n",
        "  # Convert the model using the Unified Conversion API\n",
        "  model = ct.convert(\n",
        "      keras_model,\n",
        "      source='tensorflow', \n",
        "      inputs=[image_input], \n",
        "      classifier_config=classifier_config,\n",
        "  )\n",
        "\n",
        "  print(model.input_description, '->', model.output_description)\n",
        "\n",
        "  # Set feature descriptions (these show up as comments in XCode)\n",
        "  model.input_description[input_name] = \"Input image to be classified\"\n",
        "  model.output_description[output_name] = \"Most likely image category\"\n",
        "\n",
        "  # Set model author name\n",
        "  model.author = 'Converted from TF to Core ML by Anh'\n",
        "\n",
        "  # Set a version for the model\n",
        "  model.version = \"2021-08-04\"\n",
        "\n",
        "  spec = model._spec\n",
        "\n",
        "  ct.utils.rename_feature(spec, input_name, \"image\")\n",
        "  ct.utils.rename_feature(spec, output_name, \"classLabelProbs\")\n",
        "\n",
        "  print(model.input_description, '->', model.output_description)\n",
        "\n",
        "  model.save(coreml_file)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSN_sH68-jqv",
        "outputId": "005c8515-e680-4069-cb7d-7eaa78ee6e73"
      },
      "source": [
        "mnv2 = tf.keras.applications.MobileNetV2(\n",
        "    weights=\"imagenet\", \n",
        "    input_shape=(224, 224, 3,),\n",
        "    classes=1000,\n",
        ")\n",
        "convert(mnv2, 'MobileNetV2.mlmodel', input_name = 'input_1', output_name = 'classLabel')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:00<00:00,  8.74 passes/s]\n",
            "Converting Frontend ==> MIL Ops: 100%|██████████| 426/426 [00:01<00:00, 395.39 ops/s]\n",
            "Running MIL optimization passes: 100%|██████████| 18/18 [00:00<00:00, 19.59 passes/s]\n",
            "Translating MIL ==> MLModel Ops: 100%|██████████| 747/747 [00:00<00:00, 1360.12 ops/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Features(input_1) -> Features(Identity,classLabel)\n",
            "Features(image) -> Features(Identity,classLabelProbs)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGYNk_ri4PlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1ba5d9-8231-48a1-8595-dc4d9bbc60cc"
      },
      "source": [
        "mnv3 = tf.keras.applications.MobileNetV3Large(\n",
        "    weights=\"imagenet\", \n",
        "    input_shape=(224, 224, 3,),\n",
        "    classes=1000,\n",
        ")\n",
        "convert(mnv3, 'MobileNetV3Large.mlmodel', input_name = 'input_1', output_name = 'classLabel')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:00<00:00,  6.27 passes/s]\n",
            "Converting Frontend ==> MIL Ops: 100%|██████████| 722/722 [00:01<00:00, 381.11 ops/s]\n",
            "Running MIL optimization passes: 100%|██████████| 18/18 [00:01<00:00, 11.06 passes/s]\n",
            "Translating MIL ==> MLModel Ops: 100%|██████████| 1038/1038 [00:00<00:00, 1185.38 ops/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Features(input_1) -> Features(Identity,classLabel)\n",
            "Features(image) -> Features(Identity,classLabelProbs)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6hTfFHzPDs3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}